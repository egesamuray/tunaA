\documentclass{IMAGE2025}

% An example of defining macros
\newcommand{\rs}[1]{\mathstrut\mbox{\scriptsize\rm #1}}
\newcommand{\rr}[1]{\mbox{\rm #1}}

% Required packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}

% Include any additional packages from the document
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{float}\makeatletter\@ifpackageloaded{caption}{}{\usepackage{caption}}\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}\makeatother\makeatletter\makeatother\makeatletter\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}\makeatother

\begin{document}

\title{Efficient and scalable posterior surrogate for seismic inversion
via wavelet score-based generative models}

\renewcommand{\thefootnote}{\fnsymbol{footnote}} 

\author{Ege CirakmanHuseyin Tuna ErdincFelix J. Herrmann}

\maketitle

\begin{abstract}
    Seismic inversion poses significant computational challenges due to
    its high dimensionality and non-unique solutions. We propose a novel
    method integrating the Wavelet Score-Based Generative Model (WSGM)
    with Simulation-Based Inference (SBI) to enable efficient posterior
    sampling for full-waveform inference. Our approach reduces memory
    requirements (approximately 50\%) and significantly decreases
    sampling time (approximately 73\%) compared to standard score-based
    diffusion models, while preserving accuracy. Furthermore, WSGM
    naturally supports the generation of velocity models at multiple
    resolutions, leveraging its hierarchical structure. Experimental
    results on pairs of synthetic seismic images and velocity models
    demonstrate that our method enables posterior sampling for
    large-scale 2D geophysical problems and facilitates the assessment
    of uncertainties relevant to subsurface characterization.
\end{abstract}

\newcommand{\argmin}{\mathop{\mathrm{argmin}\,}\limits}
\newcommand{\argmax}{\mathop{\mathrm{argmax}\,}\limits}

\(\def\textsc#1{\dosc#1\csod} \def\dosc#1#2\csod{{\rm #1{\small #2}}}\)

\section{Introduction}\label{introduction}

Accurate subsurface characterization remains a fundamental challenge in
geophysical exploration, with seismic inversion serving as the primary
tool for reconstructing subsurface properties, such as the acoustic
wave-speed. The inverse problem of estimating velocity models from
seismic observations is inherently ill-posed due to its high
dimensionality, non-uniqueness and sensitivity to noise (Tarantola 2005;
Virieux \& Operto 2009). As noted in the literature, traditional methods
such as full-waveform inversion (FWI), that rely on point estimates,
fail to capture the full uncertainty of the problem and do not produce
posterior distributions, which is essential for informed decision-making
in reservoir characterization and management (Fichtner \emph{et al.}
2013; Siahkoohi \emph{et al.} 2022; Xiao \emph{et al.} 2025).

Recent advances in machine learning have introduced promising algorithms
to develop neural surrogates for posterior distributions. Specifically,
SBI can facilitate posterior approximation of posterior
\(p(\mathbf{x} \mid \mathbf{y})\) in Bayesian inference without explicit
evaluation of the costly likelihood/simulator, in our case directly
related to the creation of subsurface images (Cranmer \emph{et al.}
2020). SBI can be implemented using various types of generative models,
such as conditional normalizing flows (Dinh \emph{et al.} 2017) or
score-based generative models (Song \emph{et al.} 2020), each with its
own strengths and weaknesses. However, we observe that most of the
existing generative modeling approaches often overlook the multiscale
structure and long-range spatial correlations inherent in subsurface
velocity models (Rizzuti \& Vasconcelos 2024).

Based on this insight, we propose a conditional variation of WSGM (Guth
\emph{et al.} 2022) within the SBI framework to perform posterior
estimation for velocity inversion from seismic images. Our approach
leverages Daubechies (db2) wavelets to decompose the posterior across
multiple resolution scales (\(32 \times 32\) to \(256 \times 256\)),
enabling hierarchical modeling and formulation of scale-specific score
functions. This multi-scale factorization maintains consistency between
observations and velocity estimates across resolutions, while reducing
computational requirements compared to standard diffusion methods.

The key contributions of this paper are as follows: (i) the introduction
of conditional WSGM for posterior sampling in seismic inversion, (ii) a
cascaded network architecture designed to reduce memory consumption,
(iii) comprehensive experiments on synthetic datasets demonstrating
superior performance in reconstructing complex velocity structures, and
(iv) the generation of uncertainty estimates that correlate well with
errors. The remainder of the paper is organized as follows: we present
the theory, describe the experimental setup, and discuss the results,
establishing WSGM as an efficient and scalable approach for
probabilistic seismic inversion.

\section{Theory}\label{theory}

\subsection{Seismic imaging}\label{seismic-imaging}

Seismic imaging aims to reconstruct a velocity model
\(\mathbf{x} \in \mathbb{R}^n\) from seismic observations
\(\mathbf{y} \in \mathbb{R}^m\) recorded at the surface, governed by the
forward model
\(\mathbf{y} = \mathbf{\mathcal{F}}(\mathbf{x}) + \boldsymbol{\epsilon}\),
where \(\mathbf{\mathcal{F}}: \mathbb{R}^n \rightarrow \mathbb{R}^m\) is
a nonlinear operator solving the wave equation and
\(\boldsymbol{\epsilon}\) represents noise (Virieux \& Operto 2009). The
inverse problem is ill-posed, non-uniqueness (e.g.,
\(\mathbf{\mathcal{F}}(\mathbf{x}_1) \approx \mathbf{\mathcal{F}}(\mathbf{x}_2) \approx \mathbf{y}\))
and computational expensive due to its high dimensionality. Traditional
full-waveform inversion (FWI) minimizes
\(\|\mathbf{\mathcal{F}}(\mathbf{x}) - \mathbf{y}\|_2^2\) misfit
objective to estimate \(\mathbf{x}\), but it provides only point
estimates without systematic uncertainty quantification (Virieux \&
Operto 2009). In contrast, our study targets estimation of the posterior
\(p(\mathbf{x} \mid \mathbf{y})\) in the Bayesian inference setting
using the WSGM with SBI.

\subsection{SBI for posterior
estimation}\label{sbi-for-posterior-estimation}

SBI proposes to directly estimate posterior
\(p_{\theta}(\mathbf{x} \mid \mathbf{y})\) using simulated data pairs
\(\mathcal{D} = \{ (\mathbf{x}_i, \mathbf{y}_i) \}_{i=1}^{N}\), where
\(\mathbf{x}_i\)'s are generated via the forward model, and train
conditional generative models without explicit likelihood
\(p(\mathbf{y} \mid \mathbf{x})\) computation, which can be costly or
physically impossible in many scientific settings (Cranmer \emph{et al.}
2020). A common generative model, normalizing flows can perform this
task; yet, the inherent invertible structure may cause limitations in
its performance (Rizzuti \& Vasconcelos 2024). In this work, we instead
adopt a Conditional Score-Based Generative Model---specifically,
WSGM---within the SBI framework, enabling efficient posterior estimation
across multiple scales. Notably, in our formulation \(\mathbf{y}\)
represents RTM images, which serve as summary statistics extracted from
seismic observational data (Deans 2002; Yin \emph{et al.} 2024).

\subsection{Score-based generative models (SGMs) and
WSGM}\label{score-based-generative-models-sgms-and-wsgm}

SGMs learn the gradient of the log-density (score function)
\(\nabla_{\mathbf{x}} \log p(\mathbf{x})\) using a neural network
\(s_{\boldsymbol{\theta}}(\mathbf{x})\), typically trained via a
denoising score-matching objective (Song \emph{et al.} 2020). Sampling
proceeds via Langevin dynamics (Hyv√§rinen 2005):
\(\mathbf{x}_{t+1} = \mathbf{x}_t + \eta s_{\boldsymbol{\theta}}(\mathbf{x}_t) + \sqrt{2 \eta} \mathbf{n}_t\),
where \(\mathbf{n}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\) and
\(\eta\) is the step size. While SGMs have shown impressive results in
image synthesis tasks (Ho \emph{et al.} 2020), their application in
scientific domains such as geophysics poses additional challenges. In
these settings, score functions can be highly ill-conditioned due to
long-range spatial correlations in the data, which result in poorly
conditioned covariance structures. This makes both the training and
sampling procedures significantly slower and more memory-intensive.

WSGM addresses these challenges through a multi-scale decomposition.
WSGM proposes to decompose data into scaling coefficients,
\(\mathbf{x}_j = \gamma_j^{-1} \mathbf{G} \mathbf{x}_{j-1}\), and detail
coefficients,
\(\bar{\mathbf{x}}_j = \gamma_j^{-1} \bar{\mathbf{G}} \mathbf{x}_{j-1}\),
using orthonormal wavelet filters \(\mathbf{G}\) and
\(\bar{\mathbf{G}}\) where \(j\) and \(\gamma_j\) denote scale and scale
dependent normalization, respectively. After completing the scale-wise
decomposition, WSGM learns a separate score model for each scale. In
other words, score estimation is performed through a hierarchical
architecture, progressing from coarse to fine scales. Importantly, at
each scale, the generation of detail coefficients is conditioned on the
corresponding scaling coefficients. A key innovation in WSGM is the use
of scale-specific normalization, where each scale is normalized based on
its own mean and standard deviation. This results in faster whitening
and accelerates the learning of scale-specific score functions. We argue
that the wavelet-based scale decomposition in WSGM is particularly
effective for seismic inversion problems, as velocity models naturally
exhibit strong scale-dependent features and long-range spatial
correlations.

\subsection{Training objective and conditional
WSGM}\label{training-objective-and-conditional-wsgm}

To enable posterior estimation in seismic inversion, we extend SGM and
WSGM to learn the conditional score
\(\nabla_{\mathbf{x}} \log p(\mathbf{x} \mid \mathbf{y})\). For SGM,
this involves training a network
\(s_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{y}, \sigma(t))\) to
approximate the score via a denoising objective conditioned on
\(\mathbf{y}\) (Batzolis \emph{et al.} 2021; Song \emph{et al.} 2024).
Given paired data \((\mathbf{x}, \mathbf{y})\), the objective becomes:

\[
\widehat{\boldsymbol{\theta}}_{\text{SGM}} = \mathop{\mathrm{argmin}\,}\limits_{\boldsymbol{\theta}}\mathbb{E}_{\mathbf{y},\mathbf{x}, \mathbf{n}} \left\| s_{\boldsymbol{\theta}}(\mathbf{x} + \mathbf{n}, \mathbf{y}, \sigma(t)) - \mathbf{x} \right\|_2^2
\]

where
\(\mathbf{n} \sim \mathcal{N}(\mathbf{0}, \sigma(t)^2 \mathbf{I})\) and
\(\sigma(t)\) follows a noise schedule (Karras \emph{et al.} 2022).

For WSGM (Guth \emph{et al.} 2022), the multi-scale structure enables
hierarchical conditioning and modeling. The posterior density can be
expressed by hierarchical factorization as follows:

\[
p(\mathbf{x} \mid \mathbf{y}) = p(\mathbf{x}_J \mid \mathbf{y}_J) \prod_{j = 1}^{J} p(\overline{\mathbf{x}}_j \mid \mathbf{x}_j, \overline{\mathbf{y}}_j)
\]

where \(\mathbf{x}_j\) is the velocity approximation at scale \(j\),
formed via normalized wavelet transform (WT) as
\(\text{WT}(\mathbf{x}_{j}) = (\mathbf{x}_{j+1}, \overline{\mathbf{x}}_{j+1})\)
with \(\mathbf{x}_j\) and \(\overline{\mathbf{x}}_j\) representing
scaling and detail coefficients at scale \(j\) and \(j=1\) corresponding
to the finest scale. We can reverse the process with the inverse wavelet
transform (IWT) and make similar arguments for \(\mathbf{y}_j\).

With this factorization, we have divided the learning process to
different cascaded models. The learning at the coarsest scale (\(j=J\))
can be expressed with the objective of SGM. However, for finer scales
the score network learns
\(s_{\boldsymbol{\theta}_j}(\overline{\mathbf{x}}_j, \mathbf{x}_j, \overline{\mathbf{y}}_j,\sigma(t))\).
The loss at scale \(j\) integrates these dependencies and the objective
becomes:

\[
\widehat{\boldsymbol{\theta}}_{\text{WSGM}} = \mathop{\mathrm{argmin}\,}\limits_{\boldsymbol{\theta}}\mathbb{E}_{\overline{\mathbf{y}}_j,\mathbf{x}_j,\overline{\mathbf{x}}_j,\mathbf{n}} \left\| s_{\boldsymbol{\theta}}(\overline{\mathbf{x}}_j + \mathbf{n}, \mathbf{x}_j, \overline{\mathbf{y}}_j, \sigma(t)) - \overline{\mathbf{x}}_j \right\|_2^2
\]

Posterior sampling proceeds by solving the reverse-time SDE conditioned
on unseen \(\mathbf{y}^{\text{obs}}\). For WSGM, this process occurs
sequentially: the coarsest-scale velocity \(\mathbf{x}_J\) is sampled
first, followed by detail coefficients \(\overline{\mathbf{x}}_J\),
conditioned on \(\mathbf{x}_J\) and \(\overline{\mathbf{y}}_J\). Then
inverse wavelet transform of aggregated scaling and detail coefficients
are used to proceed with finer scale and this process is repeated up to
the original scale of inputs.

\section{Experiments and Results}\label{experiments-and-results}

\subsection{Dataset creation}\label{dataset-creation}

To assess the proposed methodology, we utilize a synthetic 3D Earth
model derived from the Compass model as a representative of geological
formations in the North Sea region (E. Jones \emph{et al.} 2012). The
training dataset pairs consisting of the 2D velocities sliced through
the 3D synthetic model and reverse-time migration (RTM) pairs. The total
number of training samples is 3000 and the computational grid/resolution
is 256x256 with a spatial resolution of 6.25 m, each sample covering an
area of 3.2km x 3.2km. Seismic wave data is generated with 16 sources
and 256 receivers with a dominant frequency of 15 Hz and a recording
duration of 1.8 seconds. To simulate real-world conditions, 10 dB SNR
colored Gaussian noise is added to the shot records before migration.
The migration process for RTM is preformed with a Gaussian severely
smoothed 2D background model. Wave simulations and imaging are performed
using the open-source package JUDI (Louboutin \emph{et al.} 2023).

\subsection{Inference results}\label{inference-results}

\begin{figure}

\begin{minipage}{0.50\linewidth}

\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{./figs/rtm483.png}

\subcaption{\label{}RTM}
\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{./figs/483_velo_rainbow.png}

\subcaption{\label{}GT}
\end{minipage}%
\newline
\begin{minipage}{0.50\linewidth}

\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{./figs/gen8W.png}

\subcaption{\label{}WSGM}
\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{./figs/imagegen4WSGM.png}

\subcaption{\label{}SGM}
\end{minipage}%

\caption{\label{fig-composite}Posterior sampling results showing: (a)
initial RTM condition on which samples of posterior are conditioned, (b)
ground-truth (GT) velocity model, (c) WSGM posterior sample, and (d) SGM
posterior sample. The WSGM result shows superior preservation of
fine-scale details and reduced noise.}

\end{figure}%

\begin{figure}

\centering{

Coarse scale ~
------------------------------------------------------------------------------------------------------\textgreater{}
~ Fine scale

\includegraphics[width=0.0625\linewidth,height=\textheight,keepaspectratio]{./figs/j3_.png}
\includegraphics[width=0.125\linewidth,height=\textheight,keepaspectratio]{./figs/j2_.png}
\includegraphics[width=0.25\linewidth,height=\textheight,keepaspectratio]{./figs/j1_.png}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{./figs/WSGM_m1.png}

}

\caption{\label{fig-multiscale}Multi-scale visualization showing the
progression from coarse to fine resolution in wavelet space. The
progression represents the hierarchical nature of the wavelet
decomposition, with each level containing increasingly detailed
geological structures.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{./figs/fig3_f.png}

}

\caption{\label{fig-performance}Performance analysis and uncertainty
quantification: (a) RTM condition, (b) ground-truth velocity model (GT)
velocity, conditional mean posterior samples from (c) WSGM and (d) SGM,
the standard deviation of (e) WSGM and (f) SGM, and RMSE for (g) WSGM
and (h) SGM. Note the correlation between higher uncertainty and error
regions.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{./figs/fig4_s.png}

}

\caption{\label{fig-comparison}Comparison of GT, WSGM, and SGM.
Posterior samples for WSGM and SGM were generated starting from the same
initial noise.}

\end{figure}%

We evaluate our method by comparing posterior samples generated by WSGM
against those from standard SGM, using the same conditioning RTM image
(Figure~\ref{fig-composite}). Both methods produce velocity models that
capture the main geological structures present in the ground truth.
However, WSGM achieves this with significantly reduced computational
requirements: memory usage is approximately 50\% lower, and sampling
time is reduced by about 73\% compared to SGM.

A key advantage of our approach is the multi-scale decomposition
(Figure~\ref{fig-multiscale}), which enables hierarchical modeling from
coarse to fine scales. This decomposition naturally aligns with the
scale-dependent features present in velocity models and allows for more
efficient posterior sampling.

The performance analysis (Figure~\ref{fig-performance}) reveals that
both methods correctly identify areas of high uncertainty, which
correspond to regions where the RTM image provides limited information
due to illumination issues or complex wave propagation. Notably, WSGM's
uncertainty estimates correlate well with actual prediction errors,
suggesting that the multi-scale decomposition effectively captures the
hierarchical nature of uncertainty in the velocity model.

To further evaluate performance, we showcase results on multiple test
cases (Figure~\ref{fig-comparison}). WSGM consistently captures
long-range spatial correlations in the velocity models and produces
samples that are visually more coherent and geologically plausible than
those generated by SGM.

To quantitatively assess performance, we compute the structural
similarity index (SSIM) between posterior samples and ground truth,
finding that WSGM (SSIM = 0.87 ¬± 0.03) performs comparably to SGM (SSIM
= 0.89 ¬± 0.02). This slight difference in accuracy is outweighed by
WSGM's substantial computational advantages, especially for large-scale
applications.

\section{Conclusion}\label{conclusion}

We have presented a novel approach for seismic inversion that leverages
wavelet-based score models within a simulation-based inference
framework. Our method addresses key challenges in probabilistic seismic
inversion by:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reducing computational requirements while maintaining accuracy through
  multi-scale wavelet decomposition
\item
  Enabling efficient posterior sampling for high-dimensional velocity
  models\\
\item
  Providing reliable uncertainty quantification that correlates with
  prediction errors
\item
  Supporting multi-resolution inference through its hierarchical
  structure
\end{enumerate}

These advantages make WSGM particularly suitable for large-scale
geophysical applications where computational efficiency and uncertainty
quantification are crucial. Future work will investigate the use of
curvelet transforms to further enhance directional feature
representation, with potential application to 3D seismic volumes.

{(a) RTM} {(b) GT} {(c) WSGM} {(d) SGM} {Figure~2: Multi-scale
visualization showing the progression from coarse to fine resolution in
wavelet space. The progression represents the hierarchical nature of the
wavelet decomposition, with each level containing increasingly detailed
geological structures.} {Figure~2: Multi-scale visualization showing the
progression from coarse to fine resolution in wavelet space. The
progression represents the hierarchical nature of the wavelet
decomposition, with each level containing increasingly detailed
geological structures.} {Figure~2: Multi-scale visualization showing the
progression from coarse to fine resolution in wavelet space. The
progression represents the hierarchical nature of the wavelet
decomposition, with each level containing increasingly detailed
geological structures.} {Figure~2: Multi-scale visualization showing the
progression from coarse to fine resolution in wavelet space. The
progression represents the hierarchical nature of the wavelet
decomposition, with each level containing increasingly detailed
geological structures.} {Figure~3: Performance analysis and uncertainty
quantification: (a) RTM condition, (b) ground-truth velocity model (GT)
velocity, conditional mean posterior samples from (c) WSGM and (d) SGM,
the standard deviation of (e) WSGM and (f) SGM, and RMSE for (g) WSGM
and (h) SGM. Note the correlation between higher uncertainty and error
regions.} {Figure~4: Comparison of GT, WSGM, and SGM. Posterior samples
for WSGM and SGM were generated starting from the same initial noise.}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-batzolis2021conditional}
Batzolis, G., Stanczuk, J., Sch√∂nlieb, C.-B. \& Etmann, C., 2021.
Conditional image generation with score-based diffusion models.
\emph{arXiv preprint arXiv:2111.09217}.

\bibitem[\citeproctext]{ref-cranmer2020frontier}
Cranmer, K., Brehmer, J. \& Louppe, G., 2020. The frontier of
simulation-based inference. \emph{Proceedings of the National Academy of
Sciences}, \textbf{117}, 30055--30062, National Acad Sciences.

\bibitem[\citeproctext]{ref-deans2002maximally}
Deans, M.C., 2002. Maximally informative statistics for localization and
mapping. \emph{Proceedings 2002 IEEE international conference on
robotics and automation (cat. No. 02CH37292)}, Vol. 2, pp. 1824--1829,
IEEE.

\bibitem[\citeproctext]{ref-normalizing_flow}
Dinh, L., Sohl-Dickstein, J. \& Bengio, S., 2017. Density estimation
using real NVP. \emph{International Conference on Learning
Representations}. Retrieved from
\url{https://openreview.net/forum?id=HkpbnH9lx.}

\bibitem[\citeproctext]{ref-BG}
E. Jones, C., A. Edgar, J., I. Selvage, J. \& Crook, H., 2012. Building
complex synthetic models to evaluate acquisition geometries and velocity
inversion technologies. \emph{In 74th EAGE Conference and Exhibition
Incorporating EUROPEC 2012}, cp--293, European Association of
Geoscientists \& Engineers.
doi:\url{https://doi.org/10.3997/2214-4609.20148575}

\bibitem[\citeproctext]{ref-fichtner2013multiscale}
Fichtner, A., Trampert, J., Cupillard, P., Saygin, E., Taymaz, T.,
Capdeville, Y. \& Villase√±or, A., 2013. Multiscale full waveform
inversion. \emph{Geophysical Journal International}, \textbf{194},
534--556, Wiley Online Library.

\bibitem[\citeproctext]{ref-guth2022waveletscorebasedgenerativemodeling}
Guth, F., Coste, S., De Bortoli, V. \& Mallat, S., 2022. Wavelet
score-based generative modeling. \emph{Advances in neural information
processing systems}, \textbf{35}, 478--491.

\bibitem[\citeproctext]{ref-ho2020}
Ho, J., Jain, A. \& Abbeel, P., 2020. Denoising diffusion probabilistic
models. \emph{Advances in neural information processing systems},
\textbf{33}, 6840--6851.

\bibitem[\citeproctext]{ref-Hyvarinen2005}
Hyv√§rinen, A., 2005. Estimation of non-normalized statistical models by
score matching. \emph{Journal of Machine Learning Research}, \textbf{6},
695--709.

\bibitem[\citeproctext]{ref-karras2022elucidating}
Karras, T., Aittala, M., Aila, T. \& Laine, S., 2022. Elucidating the
design space of diffusion-based generative models. \emph{Advances in
neural information processing systems}, \textbf{35}, 26565--26577.

\bibitem[\citeproctext]{ref-judi}
Louboutin, M., Witte, P., Yin, Z., Modzelewski, H., Kerim, Costa, C. da
\& Nogueira, P., 2023, March. Slimgroup/JUDI.jl: v3.2.3, Zenodo.
doi:\href{https://doi.org/10.5281/zenodo.7785440}{10.5281/zenodo.7785440}

\bibitem[\citeproctext]{ref-rizzuti2024multiscale}
Rizzuti, G. \& Vasconcelos, I., 2024. Multiscale uncertainty
quantification for post-stack seismic inversion with wavelet flows.
\emph{Geophysical Journal International}, \textbf{229}, 1592--1607.
doi:\href{https://doi.org/10.1093/gji/ggad518}{10.1093/gji/ggad518}

\bibitem[\citeproctext]{ref-siahkoohi2022deep}
Siahkoohi, A., Rizzuti, G. \& Herrmann, F.J., 2022. Deep bayesian
inference for seismic imaging with tasks. \emph{Geophysics},
\textbf{87}, S281--S302.
doi:\href{https://doi.org/10.1190/geo2021-0666.1}{10.1190/geo2021-0666.1}

\bibitem[\citeproctext]{ref-song2024fwi}
Song, Y., Lopez, O., Yang, X. \& Ravasi, M., 2024. Score-based
generative modeling for full waveform inversion with an application to
nonlinear ultrasound imaging. \emph{arXiv preprint arXiv:2411.06651}.

\bibitem[\citeproctext]{ref-song2020score}
Song, Y., Sohl-Dickstein, J., Kingma, D.P., Kumar, A., Ermon, S. \&
Poole, B., 2020. Score-based generative modeling through stochastic
differential equations. \emph{arXiv preprint arXiv:2011.13456}.

\bibitem[\citeproctext]{ref-Tarantola2005InverseProblemTheory}
Tarantola, A., 2005. \emph{Inverse problem theory: Methods for data
fitting and model parameter estimation}, SIAM: Society for Industrial;
Applied Mathematics.

\bibitem[\citeproctext]{ref-virieux2009overview}
Virieux, J. \& Operto, S., 2009. An overview of full-waveform inversion
in exploration geophysics. \emph{Geophysics}, \textbf{74}, WCC1--WCC26,
Society of Exploration Geophysicists.

\bibitem[\citeproctext]{ref-XIAO2025112160}
Xiao, Z., Rao, J., Eisentr√§ger, S., Yuen, K.-V. \& Hadigheh, S.A., 2025.
Generative adversarial network-based ultrasonic full waveform inversion
for high-density polyethylene structures. \emph{Mechanical Systems and
Signal Processing}, \textbf{224}, 112160.
doi:\url{https://doi.org/10.1016/j.ymssp.2024.112160}

\bibitem[\citeproctext]{ref-yin2024wise}
Yin, Z., Orozco, R., Louboutin, M. \& Herrmann, F.J., 2024. WISE:
Full-waveform variational inference via subsurface extensions.
\emph{Geophysics}, \textbf{89}, A23--A28, Society of Exploration
Geophysicists.

\end{CSLReferences}

\bibliographystyle{IMAGE2025}  % style file is seg.bst
\bibliography{abstract.bib}

\end{document}
